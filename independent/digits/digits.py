from datetime import datetime
from pathlib import Path
from typing import List, Tuple

# import matplotlib.pyplot as plt
# import torch
from torch import nn
from torch.optim import SGD
import torch.utils.data
from torchvision import datasets, io as torchvision_io, transforms
from torchvision.transforms import functional as transforms_functional


# https://towardsdatascience.com/handwritten-digit-mnist-pytorch-977b5338e627


# Hyperparameters
do_training = True
hidden_sizes = [128, 64]
output_size = 10
epochs = 60
batch_size = 32
learning_rate = 0.003
momentum = 0.9

dataset_save_folder = "/Users/dave/Temp/neural_net_training/datasets"
model_save_file = "/Users/dave/Temp/neural_net_training/models/digits_emnist.pt"


# Reproducibility
torch.manual_seed(2147483647)


# Load training and test data
loading_transform = transforms.Compose([
    lambda img: transforms_functional.rotate(img, -90),
    lambda img: transforms_functional.hflip(img),
    transforms.ToTensor(),
    transforms.Normalize((0.5,), (0.5,)),
])
training_dataset = datasets.EMNIST(
    dataset_save_folder + "/EMNIST_TRAIN",
    split="digits",
    download=True,
    train=True,
    transform=loading_transform,
)
test_dataset = datasets.EMNIST(
    dataset_save_folder + "/EMNIST_TEST",
    split="digits",
    download=True,
    train=False,
    transform=loading_transform,
)
training_loader = torch.utils.data.DataLoader(training_dataset, batch_size=batch_size, shuffle=True)
test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=True)


# # Inspect data
# images, labels = next(iter(training_loader))
# print(images.shape)
# print(labels.shape)
# image = images[0]
# plt.imshow(image.squeeze(), cmap='gray_r')
# plt.show()


if do_training:
    # Construct neural net
    model = nn.Sequential(
        nn.Conv2d(in_channels=1, out_channels=6, kernel_size=5),    # 1x28x28 -> 6x24x24
        nn.ReLU(),
        nn.MaxPool2d(kernel_size=2),                                # 6x24x24 -> 6x12x12
        nn.Conv2d(in_channels=6, out_channels=16, kernel_size=5),   # 6x12x12 -> 16x8x8
        nn.ReLU(),
        nn.MaxPool2d(kernel_size=2),                                # 16x8x8 -> 16x4x4
        nn.Flatten(),                                               # 256
        nn.Linear(256, hidden_sizes[0]),                            # 128
        nn.ReLU(),
        nn.Linear(hidden_sizes[0], hidden_sizes[1]),                # 64
        nn.ReLU(),
        nn.Linear(hidden_sizes[1], output_size),                    # 10
        nn.LogSoftmax(dim=1)
    )

    # Train the model
    print("Training ...")
    criterion = nn.NLLLoss()
    optimizer = SGD(model.parameters(), lr=learning_rate, momentum=momentum)
    start_time = datetime.now()
    for epoch_num in range(epochs):
        # print(f"   starting epoch {epoch_num}")
        epoch_total_loss = 0
        for images, labels in training_loader:
            # print(f"      got {len(images)} images from training loader")
            optimizer.zero_grad()
            output = model(images)
            loss = criterion(output, labels)
            loss.backward()
            optimizer.step()
            epoch_total_loss += loss.item()

            # for image, label in zip(images, labels):
            #     if label == 9:
            #         plt.imshow(image.permute(1, 2, 0))
            #         plt.title(str(label.item()))
            #         plt.show()
        print(f"      epoch {epoch_num} training loss {epoch_total_loss / len(training_loader)}")
    print(f"Training time: {datetime.now() - start_time}")
    print("")

    # Save model
    torch.save(model, model_save_file)

    model.train(mode=False)
else:
    # Load previously saved model
    model = torch.load(model_save_file)


# Check loss and accuracy on test portion of dataset
print("Testing against test portion of dataset ...")
correct_count, all_count = 0, 0
for images, labels in test_loader:
    for i in range(len(labels)):
        image = images[i]
        input_ = torch.unsqueeze(image, 0)
        with torch.no_grad():
            output = model(input_)
        probs = torch.exp(output)
        predicted_digit = probs.argmax().item()
        labelled_digit = labels[i].item()
        if(predicted_digit == labelled_digit):
            correct_count += 1
        all_count += 1

        # plt.imshow(image.permute(1, 2, 0))
        # plt.title(str(labelled_digit))
        # plt.show()
    # break  # temp!
print(f"Tested {all_count} images, model accuracy {correct_count / all_count}.")


# Try to recognize additional images from outside the dataset
# These additional images are generated by writing with a black pen on a mostly white
# paper, and come in with grayscale integer values from 0 to 255. The training
# dataset had background color exactly-1.0 and foreground color up to 1.0, so we need to
# flip the values and scale to -1.0, 1.0 range.
print("Testing additional images ...")
additional_images_folder = Path(__file__).parent / Path("additional")
additional_images: List[Tuple[int, str, torch.Tensor]] = []
for path in additional_images_folder.glob("*.png"):
    digit = int(path.name[0])
    image_raw = torchvision_io.read_image(
        path=str(path.resolve()),
        mode=torchvision_io.ImageReadMode.GRAY,
    ).float()
    image = 2.0 - (2.0 * image_raw / 255.) - 1.0
    additional_images.append((digit, path.name, image))

for digit, filename, image in sorted(additional_images):
    input_ = torch.unsqueeze(image, 0)
    with torch.no_grad():
        output = model(input_)
    probs = torch.exp(output)
    predicted_digit = probs.argmax().item()
    did_pass = digit == predicted_digit
    print(f"   {filename} actual {digit} -> {predicted_digit} {'pass' if did_pass else 'FAIL'}")
    print(f"      probs: {probs.squeeze().tolist()}")
